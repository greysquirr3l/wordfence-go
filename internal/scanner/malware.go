// Package scanner provides the malware scanner implementation
package scanner

import (
	"context"
	"errors"
	"fmt"
	"io"
	"io/fs"
	"os"
	"path/filepath"
	"sync"
	"sync/atomic"
	"time"

	"github.com/greysquirr3l/wordfence-go/internal/intel"
	"github.com/greysquirr3l/wordfence-go/internal/logging"
)

// DefaultChunkSize is the default size for reading file chunks
const DefaultChunkSize = 1024 * 1024 // 1MB

// DefaultWorkers is the default number of worker goroutines
const DefaultWorkers = 4

// ScanResult represents the result of scanning a single file
type ScanResult struct {
	Path          string
	Matches       []*MatchResult
	Timeouts      []int
	Error         error
	ScannedBytes  int64
	ScanDuration  time.Duration
}

// HasMatches returns true if the file has any malware matches
func (r *ScanResult) HasMatches() bool {
	return len(r.Matches) > 0
}

// ScanOptions configures the scanner
type ScanOptions struct {
	Paths               []string
	Workers             int
	ChunkSize           int
	Filter              *FileFilter
	ContentLimit        int64
	AllowIOErrors       bool
	FollowSymlinks      bool
	IncludeSignatures   []int
	ExcludeSignatures   []int
}

// ScanStats holds scanning statistics
type ScanStats struct {
	FilesScanned   int64
	FilesMatched   int64
	FilesSkipped   int64
	FilesErrored   int64
	BytesScanned   int64
	TotalDuration  time.Duration
	StartTime      time.Time
	EndTime        time.Time
}

// Scanner is the malware scanner
type Scanner struct {
	matcher  *Matcher
	sigSet   *intel.SignatureSet
	options  *ScanOptions
	logger   *logging.Logger
	stats    ScanStats
	mu       sync.Mutex
}

// Option configures a Scanner
type Option func(*Scanner)

// WithScanWorkers sets the number of workers
func WithScanWorkers(workers int) Option {
	return func(s *Scanner) {
		s.options.Workers = workers
	}
}

// WithScanFilter sets the file filter
func WithScanFilter(filter *FileFilter) Option {
	return func(s *Scanner) {
		s.options.Filter = filter
	}
}

// WithScanLogger sets the logger
func WithScanLogger(logger *logging.Logger) Option {
	return func(s *Scanner) {
		s.logger = logger
	}
}

// WithAllowIOErrors sets whether to continue on IO errors
func WithAllowIOErrors(allow bool) Option {
	return func(s *Scanner) {
		s.options.AllowIOErrors = allow
	}
}

// WithContentLimit sets the maximum content size to scan per file
func WithContentLimit(limit int64) Option {
	return func(s *Scanner) {
		s.options.ContentLimit = limit
	}
}

// WithFollowSymlinks sets whether to follow symlinks
func WithFollowSymlinks(follow bool) Option {
	return func(s *Scanner) {
		s.options.FollowSymlinks = follow
	}
}

// NewScanner creates a new malware scanner
func NewScanner(sigSet *intel.SignatureSet, opts ...Option) *Scanner {
	s := &Scanner{
		sigSet: sigSet,
		options: &ScanOptions{
			Workers:   DefaultWorkers,
			ChunkSize: DefaultChunkSize,
			Filter:    DefaultFilter(),
		},
		logger: logging.New(logging.LevelInfo),
	}

	for _, opt := range opts {
		opt(s)
	}

	// Create the matcher
	s.matcher = NewMatcher(sigSet, WithMatcherLogger(s.logger))

	return s
}

// Scan scans the given paths for malware
func (s *Scanner) Scan(ctx context.Context, paths ...string) (<-chan *ScanResult, error) {
	if len(paths) == 0 {
		return nil, fmt.Errorf("no paths to scan")
	}

	s.mu.Lock()
	s.stats = ScanStats{
		StartTime: time.Now(),
	}
	s.mu.Unlock()

	results := make(chan *ScanResult, 100)
	files := make(chan string, 1000)

	// Start file locator
	go s.locateFiles(ctx, paths, files)

	// Start workers
	var wg sync.WaitGroup
	for i := 0; i < s.options.Workers; i++ {
		wg.Add(1)
		go s.worker(ctx, files, results, &wg)
	}

	// Close results when all workers are done
	go func() {
		wg.Wait()
		s.mu.Lock()
		s.stats.EndTime = time.Now()
		s.stats.TotalDuration = s.stats.EndTime.Sub(s.stats.StartTime)
		s.mu.Unlock()
		close(results)
	}()

	return results, nil
}

// locateFiles walks the file system and sends file paths to the files channel
func (s *Scanner) locateFiles(ctx context.Context, paths []string, files chan<- string) {
	defer close(files)

	visited := make(map[string]bool)

	for _, path := range paths {
		select {
		case <-ctx.Done():
			return
		default:
		}

		info, err := os.Stat(path)
		if err != nil {
			s.logger.Warning("Cannot access path %s: %v", path, err)
			continue
		}

		if info.IsDir() {
			s.walkDirectory(ctx, path, files, visited)
		} else {
			s.sendFile(ctx, path, files, visited)
		}
	}
}

// walkDirectory recursively walks a directory
func (s *Scanner) walkDirectory(ctx context.Context, dir string, files chan<- string, visited map[string]bool) {
	err := filepath.WalkDir(dir, func(path string, d fs.DirEntry, err error) error {
		select {
		case <-ctx.Done():
			return ctx.Err()
		default:
		}

		if err != nil {
			if s.options.AllowIOErrors {
				s.logger.Warning("Error accessing %s: %v", path, err)
				return nil
			}
			return err
		}

		// Skip directories
		if d.IsDir() {
			return nil
		}

		// Handle symlinks
		if d.Type()&fs.ModeSymlink != 0 {
			if !s.options.FollowSymlinks {
				atomic.AddInt64(&s.stats.FilesSkipped, 1)
				return nil
			}

			// Resolve symlink
			resolved, err := filepath.EvalSymlinks(path)
			if err != nil {
				s.logger.Debug("Cannot resolve symlink %s: %v", path, err)
				return nil
			}

			// Check for loops
			if visited[resolved] {
				return nil
			}

			info, err := os.Stat(resolved)
			if err != nil {
				return nil
			}

			if info.IsDir() {
				s.walkDirectory(ctx, resolved, files, visited)
				return nil
			}

			path = resolved
		}

		s.sendFile(ctx, path, files, visited)
		return nil
	})

	if err != nil && !errors.Is(err, context.Canceled) {
		s.logger.Warning("Error walking directory %s: %v", dir, err)
	}
}

// sendFile sends a file path to the files channel if it passes the filter
func (s *Scanner) sendFile(ctx context.Context, path string, files chan<- string, visited map[string]bool) {
	// Skip already visited files
	absPath, err := filepath.Abs(path)
	if err != nil {
		absPath = path
	}
	if visited[absPath] {
		return
	}
	visited[absPath] = true

	// Apply filter
	if s.options.Filter != nil && !s.options.Filter.Filter(path) {
		atomic.AddInt64(&s.stats.FilesSkipped, 1)
		return
	}

	select {
	case <-ctx.Done():
		return
	case files <- path:
	}
}

// worker processes files from the files channel
func (s *Scanner) worker(ctx context.Context, files <-chan string, results chan<- *ScanResult, wg *sync.WaitGroup) {
	defer wg.Done()

	for {
		select {
		case <-ctx.Done():
			return
		case path, ok := <-files:
			if !ok {
				return
			}

			result := s.scanFile(ctx, path)

			if result.Error != nil {
				atomic.AddInt64(&s.stats.FilesErrored, 1)
			} else {
				atomic.AddInt64(&s.stats.FilesScanned, 1)
				atomic.AddInt64(&s.stats.BytesScanned, result.ScannedBytes)
				if result.HasMatches() {
					atomic.AddInt64(&s.stats.FilesMatched, 1)
				}
			}

			select {
			case <-ctx.Done():
				return
			case results <- result:
			}
		}
	}
}

// scanFile scans a single file
func (s *Scanner) scanFile(ctx context.Context, path string) *ScanResult {
	start := time.Now()
	result := &ScanResult{
		Path: path,
	}

	file, err := os.Open(path) // #nosec G304 -- scanning user-specified paths
	if err != nil {
		result.Error = fmt.Errorf("failed to open file: %w", err)
		return result
	}
	defer func() { _ = file.Close() }()

	// Get file size
	info, err := file.Stat()
	if err != nil {
		result.Error = fmt.Errorf("failed to stat file: %w", err)
		return result
	}

	// Read file content
	size := info.Size()
	if s.options.ContentLimit > 0 && size > s.options.ContentLimit {
		size = s.options.ContentLimit
	}

	content, err := io.ReadAll(io.LimitReader(file, size))
	if err != nil {
		result.Error = fmt.Errorf("failed to read file: %w", err)
		return result
	}

	result.ScannedBytes = int64(len(content))

	// Match against signatures
	matchCtx := s.matcher.NewMatchContext()
	if err := matchCtx.Match(ctx, content); err != nil {
		if !errors.Is(err, context.Canceled) {
			s.logger.Debug("Match error for %s: %v", path, err)
		}
	}

	result.Matches = matchCtx.GetMatches()
	result.Timeouts = matchCtx.GetTimeouts()
	result.ScanDuration = time.Since(start)

	return result
}

// GetStats returns the current scanning statistics
func (s *Scanner) GetStats() ScanStats {
	s.mu.Lock()
	defer s.mu.Unlock()
	return s.stats
}

// ScanSingleFile scans a single file and returns the result
func (s *Scanner) ScanSingleFile(ctx context.Context, path string) *ScanResult {
	return s.scanFile(ctx, path)
}
