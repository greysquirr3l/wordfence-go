// Package scanner provides the malware scanner implementation
package scanner

import (
	"context"
	"errors"
	"fmt"
	"io"
	"io/fs"
	"os"
	"path/filepath"
	"runtime"
	"sync"
	"sync/atomic"
	"time"

	"github.com/greysquirr3l/wordfence-go/internal/intel"
	"github.com/greysquirr3l/wordfence-go/internal/logging"
)

// DefaultChunkSize is the default size for reading file chunks
const DefaultChunkSize = 1024 * 1024 // 1MB

// DefaultWorkers is the default number of worker goroutines
const DefaultWorkers = 4

// ScanResult represents the result of scanning a single file
type ScanResult struct {
	Path         string
	Matches      []*MatchResult
	Timeouts     []int
	Error        error
	ScannedBytes int64
	ScanDuration time.Duration
}

// HasMatches returns true if the file has any malware matches
func (r *ScanResult) HasMatches() bool {
	return len(r.Matches) > 0
}

// ScanOptions configures the scanner
type ScanOptions struct {
	Paths             []string
	Workers           int
	ChunkSize         int
	Filter            *FileFilter
	ContentLimit      int64
	AllowIOErrors     bool
	FollowSymlinks    bool
	IncludeSignatures []int
	ExcludeSignatures []int
	ScanDelay         time.Duration // Delay between scanning each file
	MatchTimeout      time.Duration // Timeout for regex matching

	// Advanced resource control
	MemoryLimitMB int     // Max memory usage in MB before throttling (0 = unlimited)
	IOBytesPerSec int64   // Max bytes read per second (0 = unlimited)
	BatchSize     int     // Number of files to scan before pause (0 = no batching)
	BatchPauseMS  int     // Milliseconds to pause after each batch
	MaxLoadAvg    float64 // Max system load average before throttling (0 = no limit, Unix only)
	FileQueueSize int     // Max files to queue for scanning (0 = unlimited)
}

// ScanStats holds scanning statistics
type ScanStats struct {
	FilesScanned  int64
	FilesMatched  int64
	FilesSkipped  int64
	FilesErrored  int64
	BytesScanned  int64
	TotalDuration time.Duration
	StartTime     time.Time
	EndTime       time.Time
}

// Scanner is the malware scanner
type Scanner struct {
	matcher *Matcher
	sigSet  *intel.SignatureSet
	options *ScanOptions
	logger  *logging.Logger
	stats   ScanStats
	mu      sync.Mutex

	// Resource tracking
	bytesReadThisSec int64
	lastRateReset    time.Time
	filesInBatch     int64
	rateMu           sync.Mutex

	// Dynamic throttling (set by ResourceMonitor)
	dynamicDelay atomic.Int64 // nanoseconds, checked by workers
}

// Option configures a Scanner
type Option func(*Scanner)

// WithScanWorkers sets the number of workers
func WithScanWorkers(workers int) Option {
	return func(s *Scanner) {
		s.options.Workers = workers
	}
}

// WithScanFilter sets the file filter
func WithScanFilter(filter *FileFilter) Option {
	return func(s *Scanner) {
		s.options.Filter = filter
	}
}

// WithScanLogger sets the logger
func WithScanLogger(logger *logging.Logger) Option {
	return func(s *Scanner) {
		s.logger = logger
	}
}

// WithAllowIOErrors sets whether to continue on IO errors
func WithAllowIOErrors(allow bool) Option {
	return func(s *Scanner) {
		s.options.AllowIOErrors = allow
	}
}

// WithContentLimit sets the maximum content size to scan per file
func WithContentLimit(limit int64) Option {
	return func(s *Scanner) {
		s.options.ContentLimit = limit
	}
}

// WithFollowSymlinks sets whether to follow symlinks
func WithFollowSymlinks(follow bool) Option {
	return func(s *Scanner) {
		s.options.FollowSymlinks = follow
	}
}

// WithScanDelay sets the delay between scanning each file
func WithScanDelay(delay time.Duration) Option {
	return func(s *Scanner) {
		s.options.ScanDelay = delay
	}
}

// WithScanMatchTimeout sets the timeout for regex matching in the scanner
func WithScanMatchTimeout(timeout time.Duration) Option {
	return func(s *Scanner) {
		s.options.MatchTimeout = timeout
	}
}

// WithChunkSize sets the chunk size for reading files
func WithChunkSize(size int) Option {
	return func(s *Scanner) {
		s.options.ChunkSize = size
	}
}

// WithMemoryLimit sets the maximum memory usage in MB before throttling
func WithMemoryLimit(limitMB int) Option {
	return func(s *Scanner) {
		s.options.MemoryLimitMB = limitMB
	}
}

// WithIOBytesPerSec sets the maximum bytes read per second (I/O rate limiting)
func WithIOBytesPerSec(bytesPerSec int64) Option {
	return func(s *Scanner) {
		s.options.IOBytesPerSec = bytesPerSec
	}
}

// WithBatchSize sets the number of files to scan before pausing
func WithBatchSize(size int) Option {
	return func(s *Scanner) {
		s.options.BatchSize = size
	}
}

// WithBatchPause sets the pause duration in milliseconds after each batch
func WithBatchPause(ms int) Option {
	return func(s *Scanner) {
		s.options.BatchPauseMS = ms
	}
}

// WithMaxLoadAvg sets the maximum system load average before throttling (Unix only)
func WithMaxLoadAvg(load float64) Option {
	return func(s *Scanner) {
		s.options.MaxLoadAvg = load
	}
}

// WithFileQueueSize sets the maximum number of files to queue for scanning
func WithFileQueueSize(size int) Option {
	return func(s *Scanner) {
		s.options.FileQueueSize = size
	}
}

// NewScanner creates a new malware scanner
func NewScanner(sigSet *intel.SignatureSet, opts ...Option) *Scanner {
	s := &Scanner{
		sigSet: sigSet,
		options: &ScanOptions{
			Workers:   DefaultWorkers,
			ChunkSize: DefaultChunkSize,
			Filter:    DefaultFilter(),
		},
		logger: logging.New(logging.LevelInfo),
	}

	for _, opt := range opts {
		opt(s)
	}

	// Create the matcher with optional timeout
	matcherOpts := []MatcherOption{WithMatcherLogger(s.logger)}
	if s.options.MatchTimeout > 0 {
		matcherOpts = append(matcherOpts, WithMatchTimeout(s.options.MatchTimeout))
	}
	s.matcher = NewMatcher(sigSet, matcherOpts...)

	return s
}

// Scan scans the given paths for malware
func (s *Scanner) Scan(ctx context.Context, paths ...string) (<-chan *ScanResult, error) {
	if len(paths) == 0 {
		return nil, fmt.Errorf("no paths to scan")
	}

	s.mu.Lock()
	s.stats = ScanStats{
		StartTime: time.Now(),
	}
	s.mu.Unlock()

	results := make(chan *ScanResult, 100)
	files := make(chan string, 1000)

	// Start file locator
	go s.locateFiles(ctx, paths, files)

	// Start workers
	var wg sync.WaitGroup
	for i := 0; i < s.options.Workers; i++ {
		wg.Add(1)
		go s.worker(ctx, files, results, &wg)
	}

	// Close results when all workers are done
	go func() {
		wg.Wait()
		s.mu.Lock()
		s.stats.EndTime = time.Now()
		s.stats.TotalDuration = s.stats.EndTime.Sub(s.stats.StartTime)
		s.mu.Unlock()
		close(results)
	}()

	return results, nil
}

// locateFiles walks the file system and sends file paths to the files channel
func (s *Scanner) locateFiles(ctx context.Context, paths []string, files chan<- string) {
	defer close(files)

	visited := make(map[string]bool)

	for _, path := range paths {
		select {
		case <-ctx.Done():
			return
		default:
		}

		info, err := os.Stat(path)
		if err != nil {
			s.logger.Warning("Cannot access path %s: %v", path, err)
			continue
		}

		if info.IsDir() {
			s.walkDirectory(ctx, path, files, visited)
		} else {
			s.sendFile(ctx, path, files, visited)
		}
	}
}

// walkDirectory recursively walks a directory
func (s *Scanner) walkDirectory(ctx context.Context, dir string, files chan<- string, visited map[string]bool) {
	err := filepath.WalkDir(dir, func(path string, d fs.DirEntry, err error) error {
		select {
		case <-ctx.Done():
			return ctx.Err()
		default:
		}

		if err != nil {
			if s.options.AllowIOErrors {
				s.logger.Warning("Error accessing %s: %v", path, err)
				return nil
			}
			return err
		}

		// Skip directories
		if d.IsDir() {
			return nil
		}

		// Handle symlinks
		if d.Type()&fs.ModeSymlink != 0 {
			if !s.options.FollowSymlinks {
				atomic.AddInt64(&s.stats.FilesSkipped, 1)
				return nil
			}

			// Resolve symlink
			resolved, err := filepath.EvalSymlinks(path)
			if err != nil {
				s.logger.Debug("Cannot resolve symlink %s: %v", path, err)
				return nil
			}

			// Check for loops
			if visited[resolved] {
				return nil
			}

			info, err := os.Stat(resolved)
			if err != nil {
				return nil
			}

			if info.IsDir() {
				s.walkDirectory(ctx, resolved, files, visited)
				return nil
			}

			path = resolved
		}

		s.sendFile(ctx, path, files, visited)
		return nil
	})

	if err != nil && !errors.Is(err, context.Canceled) {
		s.logger.Warning("Error walking directory %s: %v", dir, err)
	}
}

// sendFile sends a file path to the files channel if it passes the filter
func (s *Scanner) sendFile(ctx context.Context, path string, files chan<- string, visited map[string]bool) {
	// Skip already visited files
	absPath, err := filepath.Abs(path)
	if err != nil {
		absPath = path
	}
	if visited[absPath] {
		return
	}
	visited[absPath] = true

	// Apply filter
	if s.options.Filter != nil && !s.options.Filter.Filter(path) {
		atomic.AddInt64(&s.stats.FilesSkipped, 1)
		return
	}

	select {
	case <-ctx.Done():
		return
	case files <- path:
	}
}

// worker processes files from the files channel
func (s *Scanner) worker(ctx context.Context, files <-chan string, results chan<- *ScanResult, wg *sync.WaitGroup) {
	defer wg.Done()

	for {
		select {
		case <-ctx.Done():
			return
		case path, ok := <-files:
			if !ok {
				return
			}

			// Apply resource controls before scanning
			s.applyResourceControls(ctx)

			result := s.scanFile(ctx, path)

			if result.Error != nil {
				atomic.AddInt64(&s.stats.FilesErrored, 1)
			} else {
				atomic.AddInt64(&s.stats.FilesScanned, 1)
				atomic.AddInt64(&s.stats.BytesScanned, result.ScannedBytes)
				if result.HasMatches() {
					atomic.AddInt64(&s.stats.FilesMatched, 1)
				}

				// Track I/O rate after successful scan
				s.trackIORate(ctx, result.ScannedBytes)
			}

			// Check for batch pause
			s.checkBatchPause(ctx)

			select {
			case <-ctx.Done():
				return
			case results <- result:
			}
		}
	}
}

// applyResourceControls applies all configured resource throttling
func (s *Scanner) applyResourceControls(ctx context.Context) {
	// Apply dynamic delay from ResourceMonitor (if adaptive mode)
	if dynDelay := s.dynamicDelay.Load(); dynDelay > 0 {
		select {
		case <-ctx.Done():
			return
		case <-time.After(time.Duration(dynDelay)):
		}
	} else if s.options.ScanDelay > 0 {
		// Fall back to static scan delay if configured
		select {
		case <-ctx.Done():
			return
		case <-time.After(s.options.ScanDelay):
		}
	}

	// Wait for memory to be available
	s.waitForMemory(ctx)

	// Wait for system load to drop (Unix only)
	s.waitForLoad(ctx)
}

// SetDynamicDelay allows ResourceMonitor to adjust throttling in real-time
func (s *Scanner) SetDynamicDelay(d time.Duration) {
	s.dynamicDelay.Store(int64(d))
}

// scanFile scans a single file
func (s *Scanner) scanFile(ctx context.Context, path string) *ScanResult {
	start := time.Now()
	result := &ScanResult{
		Path: path,
	}

	file, err := os.Open(path) // #nosec G304 -- scanning user-specified paths
	if err != nil {
		result.Error = fmt.Errorf("failed to open file: %w", err)
		return result
	}
	defer func() { _ = file.Close() }()

	// Get file size
	info, err := file.Stat()
	if err != nil {
		result.Error = fmt.Errorf("failed to stat file: %w", err)
		return result
	}

	// Read file content
	size := info.Size()
	if s.options.ContentLimit > 0 && size > s.options.ContentLimit {
		size = s.options.ContentLimit
	}

	content, err := io.ReadAll(io.LimitReader(file, size))
	if err != nil {
		result.Error = fmt.Errorf("failed to read file: %w", err)
		return result
	}

	result.ScannedBytes = int64(len(content))

	// Match against signatures
	matchCtx := s.matcher.NewMatchContext()
	if err := matchCtx.Match(ctx, content); err != nil {
		if !errors.Is(err, context.Canceled) {
			s.logger.Debug("Match error for %s: %v", path, err)
		}
	}

	result.Matches = matchCtx.GetMatches()
	result.Timeouts = matchCtx.GetTimeouts()
	result.ScanDuration = time.Since(start)

	return result
}

// GetStats returns the current scanning statistics
func (s *Scanner) GetStats() ScanStats {
	s.mu.Lock()
	defer s.mu.Unlock()
	return s.stats
}

// ScanSingleFile scans a single file and returns the result
func (s *Scanner) ScanSingleFile(ctx context.Context, path string) *ScanResult {
	return s.scanFile(ctx, path)
}

// checkMemoryPressure returns true if we should throttle due to memory usage
func (s *Scanner) checkMemoryPressure() bool {
	if s.options.MemoryLimitMB <= 0 {
		return false
	}

	var m runtime.MemStats
	runtime.ReadMemStats(&m)

	// Alloc is bytes of allocated heap objects
	// Use uint64 comparison to avoid overflow, with safe conversion
	limitMB := s.options.MemoryLimitMB
	if limitMB < 0 {
		limitMB = 0
	}
	limitBytes := uint64(limitMB) * 1024 * 1024 //#nosec G115 -- limitMB validated non-negative
	return m.Alloc >= limitBytes
}

// waitForMemory waits until memory usage drops below the limit
func (s *Scanner) waitForMemory(ctx context.Context) {
	if s.options.MemoryLimitMB <= 0 {
		return
	}

	for s.checkMemoryPressure() {
		s.logger.Debug("Memory limit reached, waiting for GC...")
		runtime.GC() // Suggest garbage collection

		select {
		case <-ctx.Done():
			return
		case <-time.After(100 * time.Millisecond):
		}
	}
}

// trackIORate tracks bytes read and enforces I/O rate limiting
func (s *Scanner) trackIORate(ctx context.Context, bytesRead int64) {
	if s.options.IOBytesPerSec <= 0 {
		return
	}

	s.rateMu.Lock()

	now := time.Now()

	// Reset counter every second
	if now.Sub(s.lastRateReset) >= time.Second {
		s.bytesReadThisSec = 0
		s.lastRateReset = now
	}

	s.bytesReadThisSec += bytesRead

	// If we've exceeded our rate, sleep for the remainder of the second
	if s.bytesReadThisSec >= s.options.IOBytesPerSec {
		sleepDuration := time.Second - now.Sub(s.lastRateReset)
		if sleepDuration > 0 {
			s.rateMu.Unlock() // Release lock while sleeping
			select {
			case <-ctx.Done():
				// Context cancelled - exit without reacquiring lock
				return
			case <-time.After(sleepDuration):
				// Sleep complete - reacquire lock to reset counters
				s.rateMu.Lock()
				s.bytesReadThisSec = 0
				s.lastRateReset = time.Now()
				s.rateMu.Unlock()
			}
			return
		}
	}
	s.rateMu.Unlock()
}

// checkBatchPause checks if we should pause after a batch of files
func (s *Scanner) checkBatchPause(ctx context.Context) {
	if s.options.BatchSize <= 0 || s.options.BatchPauseMS <= 0 {
		return
	}

	count := atomic.AddInt64(&s.filesInBatch, 1)
	if count < int64(s.options.BatchSize) {
		return
	}

	// Ensure only one worker performs the pause for a given batch using compare-and-swap
	if !atomic.CompareAndSwapInt64(&s.filesInBatch, count, 0) {
		// Another worker already reset and is handling the pause
		return
	}

	s.logger.Debug("Batch complete (%d files), pausing for %dms", count, s.options.BatchPauseMS)

	select {
	case <-ctx.Done():
		return
	case <-time.After(time.Duration(s.options.BatchPauseMS) * time.Millisecond):
	}
}
